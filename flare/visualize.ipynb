{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff9a4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a Jupyter Notebook cell\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import ConcatDataset\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# Import our custom project files\n",
    "from local_flare_loader import LocalFlareTask3 # Needed for load_dataset to work\n",
    "from dataset import NiftiDataset\n",
    "\n",
    "# --- 1. CONFIGURE YOUR VISUALIZATION ---\n",
    "\n",
    "# Path to your local dataset\n",
    "LOCAL_DATASET_PATH = \"/mnt/asgard6/data/FLARE-MedFM/FLARE-Task3-DomainAdaption\"\n",
    "\n",
    "# Choose which dataset split to view. Options:\n",
    "# 'train_ct_gt', 'train_ct_pseudo_aladdin', 'train_ct_pseudo_blackbean',\n",
    "# 'validation_mri', 'validation_pet', 'train_mri_unlabeled', 'train_pet_unlabeled'\n",
    "DATASET_CONFIG_NAME = 'train_mri_unlabeled' \n",
    "\n",
    "# Choose which sample from that split to visualize (e.g., the 10th patient)\n",
    "SAMPLE_INDEX = 2\n",
    "\n",
    "# ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "200467a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading configuration: 'train_mri_unlabeled' ---\n",
      "--- Visualizing sample index: 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9171573954284be4845b60292c2371f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4817 samples found in the dataset.\n",
      "\n",
      "Image shape: (72, 512, 512)\n",
      "Label shape: ()\n",
      "Dataset has labels: False\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter Notebook cell\n",
    "\n",
    "print(f\"--- Loading configuration: '{DATASET_CONFIG_NAME}' ---\")\n",
    "print(f\"--- Visualizing sample index: {SAMPLE_INDEX} ---\")\n",
    "\n",
    "# Load the Hugging Face dataset object (contains file paths)\n",
    "hf_dataset = load_dataset(\n",
    "    \"./local_flare_loader.py\", \n",
    "    name=DATASET_CONFIG_NAME, \n",
    "    data_dir=LOCAL_DATASET_PATH, \n",
    "    trust_remote_code=True\n",
    ")[\"train\"]\n",
    "\n",
    "print(len(hf_dataset), \"samples found in the dataset.\")\n",
    "# Create our PyTorch NiftiDataset\n",
    "pytorch_dataset = NiftiDataset(hf_dataset)\n",
    "\n",
    "# Get the specific sample\n",
    "sample = pytorch_dataset[SAMPLE_INDEX]\n",
    "\n",
    "# Move tensors to CPU and convert to NumPy for plotting\n",
    "# The .squeeze(0) removes the channel dimension (1, D, H, W) -> (D, H, W)\n",
    "image_3d = sample['image'].cpu().numpy().squeeze(0)\n",
    "label_3d = sample['label'].cpu().numpy()\n",
    "\n",
    "# Check if the sample has a real label or is unlabeled\n",
    "has_label = sample['label'].min() != -1\n",
    "\n",
    "print(f\"\\nImage shape: {image_3d.shape}\")\n",
    "print(f\"Label shape: {label_3d.shape}\")\n",
    "print(f\"Dataset has labels: {has_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2e5e75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017af6ff81fa4e238697e7af7e115b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=50, description='Slice:'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In a Jupyter Notebook cell\n",
    "\n",
    "def window_image(image, window_center, window_width):\n",
    "    \"\"\"\n",
    "    Applies windowing to a CT scan. This is crucial for visualizing CT data.\n",
    "    \"\"\"\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    windowed_img = image.copy()\n",
    "    windowed_img[windowed_img < img_min] = img_min\n",
    "    windowed_img[windowed_img > img_max] = img_max\n",
    "    return windowed_img\n",
    "\n",
    "def plot_slice(z):\n",
    "    \"\"\"\n",
    "    This function is called every time the slider value changes.\n",
    "    It plots the image, label, and an overlay of the two.\n",
    "    \"\"\"\n",
    "    image_slice = image_3d[z, :, :]\n",
    "    \n",
    "    # Apply a standard abdominal window for CT scans for better contrast\n",
    "    if 'ct' in DATASET_CONFIG_NAME.lower():\n",
    "        image_slice = window_image(image_slice, window_center=40, window_width=400)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # --- Plot 1: The Raw Image ---\n",
    "    axes[0].imshow(image_slice, cmap='gray')\n",
    "    axes[0].set_title(f\"Image Slice (Modality: {DATASET_CONFIG_NAME.split('_')[1].upper()})\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # --- Plot 2: The Segmentation Label ---\n",
    "    if has_label:\n",
    "        label_slice = label_3d[z, :, :]\n",
    "        axes[1].imshow(label_slice, cmap='nipy_spectral', interpolation='none')\n",
    "        axes[1].set_title(\"Segmentation Mask\")\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, 'No Label Available', ha='center', va='center', fontsize=12)\n",
    "        axes[1].set_title(\"Segmentation Mask\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # --- Plot 3: The Overlay ---\n",
    "    axes[2].imshow(image_slice, cmap='gray')\n",
    "    if has_label:\n",
    "        # Use a masked array to make the background (label 0) transparent\n",
    "        masked_label = np.ma.masked_where(label_slice == 0, label_slice)\n",
    "        axes[2].imshow(masked_label, cmap='nipy_spectral', alpha=0.5, interpolation='none')\n",
    "    axes[2].set_title(\"Image + Mask Overlay\")\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Viewing Slice Z = {z}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create the interactive slider\n",
    "# The z-axis is the first dimension of the 3D volume\n",
    "num_slices = image_3d.shape[0]\n",
    "interact(plot_slice, z=IntSlider(min=0, max=num_slices - 1, step=1, value=num_slices // 2, description='Slice:'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71ce2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_image(image, window_center, window_width):\n",
    "    \"\"\"\n",
    "    Applies CT windowing for better visualization.\n",
    "    \"\"\"\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    windowed_img = image.copy()\n",
    "    windowed_img[windowed_img < img_min] = img_min\n",
    "    windowed_img[windowed_img > img_max] = img_max\n",
    "    return windowed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a147c23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 110\n"
     ]
    }
   ],
   "source": [
    "# check folder\n",
    "\n",
    "import os\n",
    "\n",
    "list_dirs1 = os.listdir(os.path.join(LOCAL_DATASET_PATH, \"validation\", \"MRI_imagesVal\")) \n",
    "# list_dirs2 = os.listdir(os.path.join(LOCAL_DATASET_PATH, \"train_MRI_unlabeled\", \"LLD-MMRI-3984\"))  \n",
    "print(len(list_dirs1), len(list_dirs1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b87582d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': '/mnt/asgard6/data/FLARE-MedFM/FLARE-Task3-DomainAdaption/validation/PET_labelsVal/fdg_1bb48bfb40_12-02-2000-NA-PET-CT_Ganzkoerper__primaer_mit_KM-90244.nii.gz',\n",
       " 'label_path': 'N/A'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c63d3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image_path', 'label_path'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(\n",
    "    \"./local_flare_loader.py\", \n",
    "    name=\"train_ct_gt\", \n",
    "    data_dir=LOCAL_DATASET_PATH, \n",
    "    # trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee2edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
